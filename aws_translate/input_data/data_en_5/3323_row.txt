Multilingual computer processing refers to the ability of a computer system to process, analyze, and manipulate text, data, and communication in multiple languages. It involves the use of various techniques, algorithms, and tools to handle different character sets, language rules, and cultural nuances, thus enabling the exchange of information between people and systems across diverse language barriers.

The given statement about Unicode as an answer to the question is partly correct as it addresses only one component of multilingual computer processing. To provide a more comprehensive answer, the focus should be on broader aspects of multilingual processing, which includes but is not limited to character encodings like Unicode.

Multilingual computer processing comprises various levels of language processing, such as:

1. Character encoding: This is the first level of multilingual processing, which deals with representing characters from multiple languages in computer systems. Unicode is an essential milestone in this regard, as it aims to standardize character encoding and provide a unique code point for every character in use worldwide. By transcending the limitations of traditional character encoding schemes like the ISO 8859 standard, Unicode allows computer systems to handle text from diverse languages consistently and efficiently.

2. Text processing: At this level, multilingual computer processing involves handling different writing systems, word segmentation, normalization, text directionality, and other language-specific features. For example, certain languages don't have spaces between words, and some have right-to-left writing systems. Computer systems need to be able to identify and process these variations to support multilingual text processing.

3. Natural language processing (NLP): This is a higher level of multilingual processing, which deals with understanding, interpreting, and generating human language in a form that computers can understand. It involves tasks like language detection, translation, information extraction, sentiment analysis, and text generation. NLP algorithms need to be designed and trained to work effectively with multiple languages, considering their grammar, syntax, and semantics.

4. Localization and internationalization: Localization refers to the process of adapting a software application's user interface and content for different languages, cultures, and locales. Internationalization involves designing software applications to support multiple languages and cultural conventions without modifications. To achieve this, developers follow programming practices and standards that ensure easy adaptation for diverse languages and regions.

In conclusion, Unicode is an essential aspect of multilingual computer processing as it facilitates the representation of characters and symbols from multiple languages. However, it is only one aspect of the broader field of multilingual computer processing, which encompasses text processing, natural language processing, localization, and internationalization. To provide a comprehensive answer to the question, it's crucial to widen the discussion to include these additional elements and demonstrate how they collectively contribute to effective multilingual processing in computer systems.