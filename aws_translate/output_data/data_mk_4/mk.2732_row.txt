Со оглед на дефиницијата и влезот на задачата, одговорете со излез. Во оваа задача, ви се дава дел од една статија. Ваша задача е да генерирате наслов (наслов) за овој текст. Преферираните наслови се под петнаесет зборови.

Наредените деноирачки автоматски енкодери (DAEs) се добро познати за да научат корисни длабоки претстави, кои можат да се користат за подобрување на надгледуваната обука со иницијализирање на длабока мрежа. Ние истражуваме шема за обука на длабок DAE, каде што постепено се додаваат слоевите DAE и продолжуваме да се адаптираме како што се додаваат дополнителни слоеви. Покажуваме дека во режимот на податочни сетови со средна големина, оваа постепена обука обезбедува мало, но конзистентно подобрување во однос на наредената обука и во квалитетот на реконструкцијата и грешката во класификацијата над наредената обука на податочни сетови на MNIST и CIFAR. 1 ПОСТАПНА ОБУКА НА ОТКРИВАЊЕ НА АВТОЕНКОДЕРИ Ние тестираме тука постепена обука на длабоки означувачки авто енкодери, обука на мрежниот слој по слој, но пониските слоеви продолжуваат да се прилагодуваат во текот на обуката. За да се овозможи пониските слоеви постојано да се прилагодуваат, бучавата се инјектира на влезно ниво. Оваа постапка за обука се разликува од магацинот обука на авто енкодери (Vincent et al., 2010) Поконкретно, во постепена обука, првиот слој на длабокиот DAE е обучен како во наредена обука, произведувајќи слој на тежини w1. Потоа, при додавање на вториот слој autoencoder, неговите тежини w2 се подесени заеднички со веќе обучените тежини w1. Со оглед на примерок за обука x, генерираме бучна верзија x, ја храниме со 2-слоевит DAE и го пресметуваме активирањето на следните слоеви h1 = Сигмоид (w > 1 x), h2 = Сигмоид (w > 2 h1) и y = Сигмоид (w ′> 3 h2). Поважно, функцијата за загуба се пресметува преку влезот x, и се користи за ажурирање на сите тежини, вклучувајќи w1. Слично на тоа, ако е обучен 3-ти слој, тоа вклучува подесување w1 и w2 покрај w3 и w′ 4. 2 ЕКСПЕРИМЕНТАЛНИ ПРОЦЕДУРИ Ги споредуваме перформансите на постепена и наредена обука во две поставки за учење: ненадгледувана задача за негирање и надгледувана задача за класификација иницијализирана со користење на тежините научени на ненадгледуван начин. Оценките беа направени на три одредници: MNIST, CIFAR-10 и CIFAR100, но само покажуваат тука MNIST резултати поради вселенските ограничувања. Ние се користи тест подмножество од 10.000 примероци и неколку големини на обука-сет сите одржување на униформа дистрибуција во текот на класи. Хипер параметрите беа избрани со користење на второ ниво на вкрстена валидација, вклучувајќи ја стапката на учење, големината на серијата SGD, моментумот и распаѓањето на тежината. Во надгледуваните експерименти, обуката била “рано запрена” по 35 епохи без подобрување. Резултатите пријавени подолу се просеци над 3 поделби за валидација на воз. Бидејќи постепената обука вклучува ажурирање на пониските слоеви, секоја презентација на примерок вклучува повеќе ажурирања на тежината отколку во еднослоен DAE. За да се споредат наредени и постепено обука на заедничка основа, ние ограничена постепена обука за користење на истиот буџет на чекори за ажурирање на тежината како наредени обука. На пример, кога го тренираме вториот слој за n епохи во постепена обука, издвојуваме 2n епохи за обука за наредени обуки (детали во целосниот труд). 1 ar X iv:1 50 4. 02 90 2v 1 [cs .L G] 1 1 A pr 2 01 5 Прифатен како придонес за работилница на ICLR 2015 a) Ненадгледувана обука б) Надгледувана обука 0 0.25 0.5 10.4 10,5 10,6 10,7